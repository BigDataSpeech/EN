---
layout: post
title:  "NER : système avec CRF (Sophie Rosset et Maud Ehrmann)"
date:   2018-06-15 11:38:36 +0100
categories: NER projet
---

* Table des matières
{:toc}


## Description générale
{:.no_toc}
Il s'agit de développer un système à base d'apprentissage automatique avec l'outil Wapiti.
La documentation se trouve [cette page](https://wapiti.limsi.fr/manual.html).
Les types d'entités à détecter sont les _pers et les _time. Il s'agit
des types les plus extérieurs (version simplifiée). La version complète
du guide d'annotation est disponible [ici](https://github.com/BigDataSpeech/EN/blob/gh-pages/docs/quaero-guide-annotation-2011.pdf).

```
Exemple de simplification
comment  <pers.ind>  <name.first> Eric  </name.first>  <name.last> Woerth  </name.last>  </pers.ind>

devient

comment  <pers> Eric  Woerth </pers>
```

Tout ce qui se rapporte au développement de ce système à base de règles se trouve l'archive [disponible ici](https://github.com/BigDataSpeech/EN/blob/gh-pages/docs/sys-crf.tar.gz).

## Objectifs

L'objectif pour ce TP est de développer un système de détection
d'entités avec l'outil wapiti et de procéder à des évaluations et des
analyses des résultats.

## Récupération et décompression de l'archive

Vous pouvez télécharger l'archive en cliquant sur [ce
lien](https://github.com/BigDataSpeech/EN/blob/gh-pages/docs/sys-crf.tar.gz).

Vous lancez ensuite la commande :
```
tar xvfz sys-crf.tar.gz
```
Pour changer automatique les chemins dans l'ensemble des scripts, tapez
la commande suivante :

```
cd syst-crf
./change-path.sh `pwd`
```

### Structure de l'archive

L'archive contient, outre les deux scripts liés au changement automatique de paths, un ensemble de répertoire ainsi que le système de base et les ressources utiles.

La structure est la suivante :

* bin	     <-- les exécutables (voir plus bas)
* data	     <-- les données (voir plus bas)
* hyp	     <-- le répertoire où vous mettrez les sorties de vos systèmes
* models     <-- le répertoire où sauvegarder les modèles appris avec wapiti
* patterns   <-- le répertoire où mettre les fichiers de pattern
* res	     <-- le répertoire où mettre les résultats des évaluations
* scripts    <-- un répertoire contenant des scripts utiles
  * BIO-to-xml.awk : passer du format BIO au format xml (simple)
  * BIO-to-Full-xml.awk : passer du format BIO au format xml (arbres complets)
  * apply.sh : appliquer un modèle sur un fichier
  * all_asr_apply.sh : appliquer un modèle sur tous les fichiers asr
  * asr_apply.sh : appliquer un modèle sur un fichier asr
  * all_asr_eval.sh : évaluer sur tous les dichiers asr
  * asr_eval.sh : évaluer sur un fichier asr
  * config.lua : fichier de confirguration pour évaluation
  * eval.sh : évaluer sur un fichier transcription manuelle
  * learn.sh : apprendre un modèle
  * pos.lua : annotation en POS
  * pos.sh : lacement annotation en POS
  * xml-to-bio.awk : passer du format xml au format bio

### Récupération des outils

L'ensemble des outils compilés utiles (voire indispensables) se trouvent
sur [ce site](https://sr.kervella.org/soft4BDS/). Récupérez-les
et mettez-les dans le répertoire bin/

Ensuite, allez dans le répertoire bin/ et rendez exécutable les programmes.

```
cd bin/
chmod 755 *

```
## Données

Vous disposez des données d'apprentissage de ETAPE annotées avec la
version simplifiée du guide. Celle-ci comprend la version annotée
uniquement avec les *_pers* et les *_time* et la version avec tous les
types (plus haut niveau à chaque fois, c'est à dire *_amount*,
*_func*, *_loc*, *_org*, *_prod*, ainsi que *_pers* et *_time*). Ces
données sont disponibles dans deux formats :

* bio : un mot par ligne ; la deuxième colonne contient le type de
  l'entité. Il s'agit donc d'un format *tabulaire* (comme une
  table). Exemple :

Exemple:
```
comment   o
Eric 	  b-_pers
Woerth 	  i-_pers
peut-il   o
encore 	  o
euh 	  o
```

* sgml : une "phrase" par ligne, les entités sont entourés par des
  tags sgml. Exemple :

Exemple:
```
comment <_pers> Eric Woerth </_pers> peut-il encore euh
```

Ces données sont disponibles dans le répertoire data. Vous disposez
des données :

* pour l'apprentissage : transcrites manuellement et annotées
  manuellement au format sgml et bio avec différentes typologies
  (complète, simplifiée et ultra-simplifiée)
* pour le test : transcrites manuellement annotée pour la référence ou
  non annotée et transcrites automatiquement annotées manuellement par
  projection et non annotées.

L'organisation de ce répertoire est la suivante :

```
data
 trn						<-- données annotées
 						apprentissage/développement
  train_Etape_Complet_u8.bio
  train_Etape_Complet_u8.sgml
  train_Etape_POS.bio
  train_Etape_SimplifiedPERS+TIME_POS_u8.bio
  train_Etape_SimplifiedPERS+TIME_u8.bio
  train_Etape_SimplifiedPERS+TIME_u8.sgml
  train_Etape_Simplified_u8.bio
  train_Etape_Simplified_u8.sgml
 test						<-- données d'évaluation
  asr
   rover/*.txt
   s23/*.txt
   s25/*.txt
  man						<-- données textes simples
   test_man_Etape_u8.bio
   test_man_Etape_u8.txt
  references					<-- données de références
  						    (annotées)
   asr						<-- transcriptions automatiques
   						(projection/aref)
    rover/*.aref
    s23/*.aref
    s25/*aref
   man						<-- transcriptions manuelles
    test_man_Etape_Complet_u8.bio
    test_man_Etape_Complet_u8.sgml
    test_man_Etape_SimplifiedPERS+TIME_u8.bio
    test_man_Etape_SimplifiedPERS+TIME_u8.sgml
    test_man_Etape_Simplified_u8.bio
    test_man_Etape_Simplified_u8.sgml
    test_man_Etape_Simplified_u8.sgml
```

## Wapiti

Wapiti est une boîte à outil dédiée à la segmentation et à
l’étiquetage de séquences développée au LIMSI par Thomas Lavergne. Ce
logiciel intègre plusieurs modèles (MaxEnt, MEMM, CRF). Ici nous
utiliserons les CRF qui sont les plus appropriés pour la détection et
la reconnaissance des entités nommées. Son manuel est consultable à
[cette page](https://wapiti.limsi.fr/manual.html).

La syntaxe générale est :

```
wapiti mode [options] [input] [output]
```

## Apprentissage

Pour apprendre un modèle CRF sur un corpus, il faut d'une part
disposer de celui-ci au format BIO (c'est le cas) et d'autre part
définir les features qu'il aura à utiliser (c'est à dire les
caractéristiques utiles pour apprendre).  Ces features sont définis
sous la forme de patrons dans un fichier texte. La syntaxe des patrons
est définie sur [cette
page](https://wapiti.limsi.fr/manual.html#patterns).

Le fichier de patron considère le token courant du fichier donné en
entrée (on le note %x). Par exemple :

```
colonnes: 0	  1
          comment o
	  Eric    b-_pers <<--- token courant
	  Woerth  i-_pers
	  peut-il o
	  encore  o
	  euh     o
```

Il indique les informations utilisées pour étiqueter ce token. Les
informations sont référencées par leur position (ligne) par rapport au
token courant, et leur type (colonne). Par exemple ``` %x[-1,0] =>
comment ``` définit le token "comment" comme un feature. En effet, il
indique qu'il faut regarder la ligne au-dessus de x (Eric) et sur
cette ligne la colonne 0 (c'est à dire la première colonne).

La syntaxe de ses patrons permet non seulement de dire que tel ou tel
élément de telle ou telle ligne ou colonne doit être utilisé mais
également si ce token appartient à un classe donnée. Par exemple :

```
# le token commence par une majuscule ? (BegC)

*:BegC? X=%t[ 0,0,"^\u"]
```

vérifie si le mot courant commence par une majuscule.

Vous disposez d'un fichier de patron simples que vous pourrez
améliorer, notamment en intégrant d'autres informations comme les
parties du discours (voir plus bas). Ce fichier se trouve dans
le répertoire **patterns/**.


L'organisation de cette archive est :
```
system-crf
   hyp:
     test_Etape_MPM.bio
     test_Etape_MPM.sgml

   models:
     mon_premier_model

   patterns:
     basic-patterns.txt

   scripts:
     learn.sh
     apply.sh
     eval.sh
     config.lua
     BIO-to-xml.awk
     xml-to-bio.awk
```

### Améliorations

Pour améliorer le système vous pouvez enrichir ses features. Par exemple, vous pouvez utiliser des annotations en partie du discours (POS) et ajouter des patrons qui en tiennent compte.

Vous disposez dans le répertoire script, d'un script *pos.sh* qui annote un fichier en POS et remet le tout en format *tabulaire*. La deuxième colonne contient les POS. Il ressemble à ceci :

Exemple:
```
comment o
Eric    b-_pers
Woerth  i-_pers
peut-il o
encore  o
euh     o
```




## Evaluations

Pour évaluer votre système, vous devez comparer ses hypothèses (sa
sortie analysée) avec la référence. Pour cela vous disposez d'un
logiciel qui vous permet d'obtenir les scores mais aussi les listes
des différentes erreurs et de ce qui est bon dans un format texte
lisible dans n'importe quel éditeur.

Ce logiciel, ne-scoring-gen, prend en paramètre un fichier de
configuration (config.lua), un fichier de référence (annotations
manuelles) et un fichier d'hypothèses (annotations automatiques). Il
propose différentes options.

```
NE scoring

Usage: ne-scoring-gen [options] descr.lua ref-file hyp-file
  -a                  reference is in "aref" format
  -s                  show summary of results (default)
  -d                  show detail of errors
  -c                  show detail of errors and corrects
  -i <expected_count> show IAG-type values
  -o                  open - in IAG mode, there are no confusions
```

Vous disposez dans le répertoire scripts/ d'un ensemble de scripts
permettant de faire différentes évaluations. Il s'agit de modèles que
vous pourrez développer plus avant, selon vos besoins.
