---
layout: post
title:  "NER : système à base de règles (Sophie Rosset et Maud Ehrmann)"
date:   2018-06-15 11:38:36 +0100
categories: NER projet
---

* Table des matières
{:toc}


## Description générale
{:.no_toc}

Il s'agit de développer un système à base de règles avec l'outil
wmatch.  Un manuel est disponible
[ici](https://github.com/BigDataSpeech/EN/blob/gh-pages/docs/wmatch_user_manual.pdf).
Les types d'entités à détecter sont les _pers et les _time. Il s'agit
des types les plus extérieurs (version simplifiée) du guide Quaero.
La version complète du guide d'annotation est disponible
[ici](https://github.com/BigDataSpeech/EN/blob/gh-pages/docs/quaero-guide-annotation-2011.pdf).

Tout ce qui se rapporte au développement de ce système à base de
règles se trouve l'archive [disponible
ici](https://github.com/BigDataSpeech/EN/blob/gh-pages/docs/sys-regles.tar.gz).


## Objectifs

L'objectif pour ce TP est de développer un système de détection
d'entités avec un système à base de règles et de procéder à des
évaluations et des analyses des résultats.

## Récupération et décompression de l'archive

Vous pouvez télécharger l'archive en cliquant sur [ce
lien](https://github.com/BigDataSpeech/EN/blob/gh-pages/docs/sys-regles.tar.gz).

Vous lancez ensuite la commande :
```
tar xvfz sys-regles.tar.gz
```
Pour changer automatique les chemins dans l'ensemble des scripts, tapez
la commande suivante :

```
./change-paths.sh `pwd`
```

### Structure de l'archive

L'archive contient un ensemble de répertoire ainsi que le système de base et les ressources utiles.

Les répertoires utiles pour le système sont :

* compwm : permet une compilation à la volée des grammaires
* dic : contient
  * french-par-linux-3.1.bin : le modèle tree tagger pour l'annotation en parties du discours
  * tt-french-mapping.txt : fichier mapping pour wmatch
  * stems-fr.txt : une ressource contenant pour chaque item, son "lemme"
* hyp : le répertoire où mettre les résultats de vos analyses
* pers-time.lua : le système
* res : le répertoire où mettre le résultat des évaluations
* data : le répertoire de données
* filtres : les filtres utilisés par le système
* listes : les ressources lexicales du système
* regles : les grammaires du systèmes
* scripts : des scripts utiles (application, évaluation, etc.)
  * BIO-to-xml.awk : passer du format BIO au format xml
  * all_asr_eval.sh : évaluer tous les fichiers asr 
  * asr_apply.sh : appliquer le système sur un fichier asr
  * config.lua : fichier de config pour évaluation
  * number-net.sed : nettoyage de la sortie de wmatch
  * all_asr_apply.sh : appliquer le système sur tous les fichiers asr
  * apply.sh : appliquer le système sur un fichier
  * asr_eval.sh : appliquer le système sur un fichier asr
  * eval.sh : faire une évaluation simple (transcription manuelle)
  * xml-to-bio.awk : passer du format xml au format bio

### Récupération des outils

L'ensemble des outils compilés utiles (voire indispensables) se trouvent
sur [ce site](https://sr.kervella.org/soft4BDS/). Récupérez-les
et mettez-les dans le répertoire bin/

## Données
Vous disposez des données d'apprentissage de ETAPE annotées avec la version
simplifiée. Celle-ci comprend la version annotée uniquement avec les
*_pers* et les *_time* et la version avec tous les types (plus haut niveau
à chaque fois, c'est à dire *_amount*, *_func*, *_loc*, *_org*, *_prod*, ainsi
que *_pers* et *_time*). Ces données sont disponibles dans deux formats :

* bio : un mot par ligne ; la deuxième colonne contient le type de l'entité. Exemple : 

```
comment		o
Eric 		b-_pers
Woerth 		i-_pers
peut-il 	o
encore 		o
euh 		o
```

* sgml : une "phrase" par ligne, les entités sont entourés par des tags sgml. Exemple :

```
comment <_pers> Eric Woerth </_pers> peut-il encore euh
```

Ces données sont disponibles dans le répertoire data. Vous disposez des données :

* pour l'apprentissage : transcrites manuellement et annotées manuellement au format sgml et bio avec différentes typologies (complète, simplifiée et ultra-simplifiée)
* pour le test : transcrites manuellement annotée pour la référence ou non annotée et transcrites automatiquement annotées manuellement par projection et non annotées.

L'organisation de ce répertoire est la suivante :

```
data
 trn						<-- données annotées
 						apprentissage/développement
  train_Etape_Complet_u8.bio
  train_Etape_Complet_u8.sgml
  train_Etape_POS.bio
  train_Etape_SimplifiedPERS+TIME_POS_u8.bio
  train_Etape_SimplifiedPERS+TIME_u8.bio
  train_Etape_SimplifiedPERS+TIME_u8.sgml
  train_Etape_Simplified_u8.bio
  train_Etape_Simplified_u8.sgml
 test						<-- données d'évaluation
  asr
   rover/*.txt
   s23/*.txt
   s25/*.txt
  man						<-- données textes simples
   test_man_Etape_u8.bio
   test_man_Etape_u8.txt
  references					<-- données de références
  						    (annotées)
   asr						<-- transcriptions automatiques
   						(projection/aref)
    rover/*.aref
    s23/*.aref
    s25/*aref
   man						<-- transcriptions manuelles
    test_man_Etape_Complet_u8.bio
    test_man_Etape_Complet_u8.sgml
    test_man_Etape_SimplifiedPERS+TIME_u8.bio
    test_man_Etape_SimplifiedPERS+TIME_u8.sgml
    test_man_Etape_Simplified_u8.bio
    test_man_Etape_Simplified_u8.sgml
    test_man_Etape_Simplified_u8.sgml
```

## Système

Vous disposez de grammaires basiques qui vous permettront de démarrer
et de scripts lancement.

### Grammaires
Les grammaires sont dans le répertoires regles/
Elles sont la forme suivante (décrite dans le [manuel wmatch](https://github.com/BigDataSpeech/EN/blob/gh-pages/docs/wmatch_user_manual.pdf)).

```
%toto: titi tata tutu;      <-- une liste appelée toto
&MacroToto: (<! non) %toto; <-- une macro qui dit que les mots de la liste %toto
	    	     	        sont matchés par MacroToto si pas précédés du
				mot non
_tata: (&MacroToto);	    <-- une expression qui entre dans &MacroToto
       			        voit s'appliquer la règle _tata.
```
### Lancement
Vous pouvez utiliser le système pour du test interactif (très pratique
quand on développe). Pour cela :

```
./pers-time.lua
le 23 juin                    -->> votre entrée 
le <_time> 23 juin </_time>   -->> réponse système
```

Vous pouvez également lancer le système sur tout un fichier et
produire la sortie dans un fichier :

```
./pers-time.lua < fichier.txt > fichier.sgml
```

### Améliorations

Pour améliorer les règles, en ajouter voire en supprimer, vous ouvrez
avec un éditeur quelconque (par exemple emacs ou gedit) le fichier de
grammaire qui vous intéresse et vous travaillez dessus.

Vous pouvez décider d'ajouter des grammaires et dans ce cas, vous
ouvrez le fichier pers-time.lua avec un éditeur et vous ajoutez une
ligne indiquant le nom de la nouvelle grammaire (sur les modèles
disponibles).

## Evaluations

Pour évaluer votre système, vous devez comparer ses hypothèses (sa
sortie analysée) avec la référence. Pour cela vous disposez d'un
logiciel qui vous permet d'obtenir les scores mais aussi les listes
des différentes erreurs et de ce qui est bon dans un format texte
lisible dans n'importe quel éditeur.

Ce logiciel, ne-scoring-gen, prend en paramètre un fichier de
configuration (config.lua), un fichier de référence (annotations
manuelles) et un fichier d'hypothèses (annotations automatiques). Il
propose différentes options.

```
NE scoring

Usage: ne-scoring-gen [options] descr.lua ref-file hyp-file
  -a                  reference is in "aref" format
  -s                  show summary of results (default)
  -d                  show detail of errors
  -c                  show detail of errors and corrects
  -i <expected_count> show IAG-type values
  -o                  open - in IAG mode, there are no confusions
```

Vous disposez dans le répertoire scripts/ d'un ensemble de scripts
permettant de faire différentes évaluations. Il s'agit de modèles que
vous pourrez développer plus avant, selon vos besoins.
